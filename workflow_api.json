{
  "35": {
    "inputs": {
      "guidance": 2.5,
      "conditioning": [
        "177",
        0
      ]
    },
    "class_type": "FluxGuidance",
    "_meta": {
      "title": "FluxGuidance"
    }
  },
  "39": {
    "inputs": {
      "vae_name": "flux/flux_ae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "42": {
    "inputs": {
      "image": [
        "142",
        0
      ]
    },
    "class_type": "FluxKontextImageScale",
    "_meta": {
      "title": "FluxKontextImageScale"
    }
  },
  "124": {
    "inputs": {
      "pixels": [
        "42",
        0
      ],
      "vae": [
        "39",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "142": {
    "inputs": {
      "image": "nirvana-wallpaper-light.jpg [output]",
      "refresh": "refresh"
    },
    "class_type": "LoadImageOutput",
    "_meta": {
      "title": "ËæìÂÖ•ÂéüÂõæ-Input"
    }
  },
  "177": {
    "inputs": {
      "conditioning": [
        "203",
        2
      ],
      "latent": [
        "124",
        0
      ]
    },
    "class_type": "ReferenceLatent",
    "_meta": {
      "title": "ReferenceLatent"
    }
  },
  "193": {
    "inputs": {
      "model_type": "flux",
      "text_encoder1": "flux/t5xxl_fp16.safetensors",
      "text_encoder2": "flux/clip_l.safetensors",
      "t5_min_length": 512,
      "use_4bit_t5": "disable",
      "int4_model": "none"
    },
    "class_type": "NunchakuTextEncoderLoader",
    "_meta": {
      "title": "Nunchaku Text Encoder Loader (Deprecated)"
    }
  },
  "199": {
    "inputs": {
      "ckpt_name": "SUPIR/SUPIR-v0Q_fp16.safetensors",
      "vae_name": "Baked VAE",
      "lora_name": "None",
      "lora_model_strength": 1,
      "lora_clip_strength": 1,
      "resolution": "1024 x 1024",
      "empty_latent_width": 1024,
      "empty_latent_height": 1024,
      "positive": [
        "223",
        0
      ],
      "batch_size": 1,
      "model_override": [
        "248",
        0
      ],
      "clip_override": [
        "193",
        0
      ],
      "vae_override": [
        "39",
        0
      ]
    },
    "class_type": "easy fluxLoader",
    "_meta": {
      "title": "EasyLoader (Flux)"
    }
  },
  "200": {
    "inputs": {
      "guider": "Basic",
      "cfg": 2.5,
      "cfg_negative": 1.5,
      "sampler_name": "euler",
      "scheduler": "simple",
      "coeff": 1.2,
      "steps": 20,
      "sigma_max": 14.614642,
      "sigma_min": 0.0291675,
      "rho": 7,
      "beta_d": 19.9,
      "beta_min": 0.1,
      "eps_s": 0.001,
      "flip_sigmas": false,
      "denoise": 1,
      "add_noise": "enable (CPU)",
      "seed": 669020242164483,
      "pipe": [
        "202",
        0
      ],
      "latent": [
        "124",
        0
      ]
    },
    "class_type": "easy preSamplingCustom",
    "_meta": {
      "title": "PreSampling (Custom)"
    }
  },
  "201": {
    "inputs": {
      "image_output": "Hide",
      "link_id": 0,
      "save_prefix": "ComfyUI",
      "pipe": [
        "200",
        0
      ]
    },
    "class_type": "easy kSampler",
    "_meta": {
      "title": "EasyKSampler"
    }
  },
  "202": {
    "inputs": {
      "pipe": [
        "203",
        0
      ],
      "pos": [
        "35",
        0
      ]
    },
    "class_type": "easy pipeIn",
    "_meta": {
      "title": "Pipe In"
    }
  },
  "203": {
    "inputs": {
      "pipe": [
        "199",
        0
      ]
    },
    "class_type": "easy pipeOut",
    "_meta": {
      "title": "Pipe Out"
    }
  },
  "205": {
    "inputs": {
      "images": [
        "201",
        1
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "209": {
    "inputs": {
      "system_prompt": "**Role**  \nYou are a professional Flux Kontext Prompt Assistant. Your expertise is in converting an image (or its description) and a user's natural language editing intent into a clear, well-structured, and actionable prompt for image modification, optimized for Flux Kontext standards.\n\n---\n\n**Objectives**  \n- Convert user input (image description and modification intent) into an English prompt that clearly specifies:\n  - What to change, using direct verbs (e.g., Change, Transform, Replace)\n  - Which elements to keep unchanged\n  - Step-by-step instructions for complex edits\n  - Consistent composition, character features, and style\n- Ensure all prompts are simple, unambiguous, and follow the provided output formats.\n\n---\n\n**Style**  \n- Use simple, straightforward English  \n- Prefer imperative verb forms  \n- Remain formal and instructive  \n- Avoid unnecessary flourish  \n\n---\n\n**Content**  \n- You have access to best practices in prompt engineering for visual AI systems.\n- The output must help an image-generation model understand exactly which elements to modify and which to preserve.\n- Typical request types include: appearance changes, style transformations, background edits, and text edits.\n- For style or action changes, generate instructions **in logical steps**.\n- When the user input is vague, clarify and specify standard modifications per guidance.\n- Use the correction table provided for common user mistakes.\n\n---\n\n**Input**  \n- **Image Description** or Image URL  \n- **User Intent:** Natural language request detailing the desired modification(s)\n\n---\n\n**Response**  \n- Output a succinct, Flux Kontext-compatible prompt in one of the following forms, as appropriate:\n  - `\"Change [object] to [new state], keep [content to preserve] unchanged\"`\n  - `\"Transform to [specific style], while maintaining [composition/character/other] unchanged\"`\n  - `\"Change the background to [new background], keep the subject in the exact same position and pose\"`\n  - `\"Replace '[original text]' with '[new text]', maintain the same font style\"`\n\n- For multi-part/complex requests, enumerate stepwise instructions with clear, single-action sentences.\n\n- Where user input is ambiguous or uses casual terms, output should clarify intent (e.g., `\"Let him become Superman\"` ‚Üí `\"Change the clothes to a superhero costume while keeping facial features and pose unchanged\"`).\n\n---\n\n**Audience**  \n- Users familiar with text-to-image generation or editing tools, seeking precise, effective prompts.\n\n---\n\n**Workflow**  \n1. Analyze the user‚Äôs provided image description and modification intent.\n2. Determine the core change requested (object, style, background, text, or multiple changes).\n3. Select the correct output template format.\n4. For complex edits, break down into ordered steps.\n5. Check and correct non-optimal requests according to best practices in the correction table.\n6. Present the final prompt in the required structure.\n\n---\n\n**Example**\n\n**User Input:**  \n- Image: A girl wearing a denim jacket stands on a city street.  \n- Request: Please change her outfit to a traditional Japanese kimono, keep the style and pose the same.\n\n**Output Prompt:**  \n\"Change the clothes to a traditional Japanese kimono while keeping the same pose, facial expression, and artistic style\"\n\n---\n\n**Additional Example (Complex/Stepwise):**  \n**User Input:**  \n- Image: A man in a suit stands in an office.  \n- Request: Change him into a medieval knight and place him in a forest, but keep his face and stance.\n\n**Output Prompt:**  \nStep 1: \"Change the background to a dense forest, keep the subject in the same position and stance\"  \nStep 2: \"Change the suit to medieval knight armor, keeping the facial features and pose unchanged\"\n\n---\n\n**Correction Example (Common Error):**  \n**User Input:** \"Make him a superhero\"\n\n**Output Prompt:**  \n\"Change the clothes to a superhero costume while keeping facial features and pose unchanged\"",
      "user_prompt": [
        "210",
        0
      ],
      "temperature": 0.7,
      "is_memory": "enable",
      "is_tools_in_sys_prompt": "disable",
      "is_locked": "disable",
      "main_brain": "enable",
      "max_length": 1920,
      "imgbb_api_key": "",
      "conversation_rounds": 100,
      "historical_record": "",
      "is_enable": true,
      "stream": false,
      "model": [
        "222",
        0
      ],
      "images": [
        "42",
        0
      ]
    },
    "class_type": "LLM",
    "_meta": {
      "title": "‚òÅÔ∏èAPI LLM general link"
    }
  },
  "210": {
    "inputs": {
      "text": "ÊääÂõæ‰∏≠ÁöÑÂ≠óÊØçÊîπÊàêBaBy"
    },
    "class_type": "Text",
    "_meta": {
      "title": "ËæìÂÖ•ÈúÄÊ±Ç-Input"
    }
  },
  "213": {
    "inputs": {
      "text_0": "\"Replace the text 'deepin' with 'BaBy', maintain the original font style and keep all other parts of the image unchanged\"",
      "text": [
        "209",
        0
      ]
    },
    "class_type": "ShowText|pysssss",
    "_meta": {
      "title": "Show Text üêç"
    }
  },
  "222": {
    "inputs": {
      "model_name": "gpt-4.1"
    },
    "class_type": "easy_LLM_api_loader",
    "_meta": {
      "title": "‚òÅÔ∏èEasy API LLM Loader"
    }
  },
  "223": {
    "inputs": {
      "string": [
        "209",
        0
      ],
      "regex_pattern": "^\"|\"$",
      "replace": "",
      "case_insensitive": true,
      "multiline": false,
      "dotall": false,
      "count": 0
    },
    "class_type": "RegexReplace",
    "_meta": {
      "title": "Regex Replace"
    }
  },
  "240": {
    "inputs": {
      "rgthree_comparer": {
        "images": [
          {
            "name": "A",
            "selected": true,
            "url": "/api/view?filename=rgthree.compare._temp_yxhek_00019_.png&type=temp&subfolder=&rand=0.023010294024340183"
          },
          {
            "name": "B",
            "selected": true,
            "url": "/api/view?filename=rgthree.compare._temp_yxhek_00020_.png&type=temp&subfolder=&rand=0.5160159981650179"
          }
        ]
      },
      "image_a": [
        "201",
        1
      ],
      "image_b": [
        "42",
        0
      ]
    },
    "class_type": "Image Comparer (rgthree)",
    "_meta": {
      "title": "Image Comparer (rgthree)"
    }
  },
  "248": {
    "inputs": {
      "boolean": false,
      "on_true": [
        "255",
        0
      ],
      "on_false": [
        "251",
        0
      ]
    },
    "class_type": "Switch any [Crystools]",
    "_meta": {
      "title": "Ë∞ÉÊï¥Ë¥®Èáè-Input"
    }
  },
  "251": {
    "inputs": {
      "model_path": "flux/svdq-int4_r32-flux.1-kontext-dev.safetensors",
      "cache_threshold": 0,
      "attention": "nunchaku-fp16",
      "cpu_offload": "auto",
      "device_id": 0,
      "data_type": "bfloat16",
      "i2f_mode": "enabled"
    },
    "class_type": "NunchakuFluxDiTLoader",
    "_meta": {
      "title": "Nunchaku FLUX DiT Loader"
    }
  },
  "252": {
    "inputs": {
      "unet_name": "flux/flux1-kontext-dev-Q8_0.gguf"
    },
    "class_type": "UnetLoaderGGUF",
    "_meta": {
      "title": "È´òË¥®ÈáèÊ®°ÂûãÔºàÈÄüÂ∫¶ÊÖ¢‰∏Ä‰∫õÔºâ"
    }
  },
  "255": {
    "inputs": {
      "model_type": "flux-kontext",
      "rel_l1_thresh": 0.13000000000000003,
      "start_percent": 0.20000000000000004,
      "end_percent": 0.9000000000000001,
      "cache_device": "cuda",
      "model": [
        "252",
        0
      ]
    },
    "class_type": "TeaCache",
    "_meta": {
      "title": "TeaCache"
    }
  }
}